{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YeZAsw7Cq_zM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9U3NjatFV9w",
        "outputId": "0b8c95f5-d316-499b-cc3c-bd3077dff84d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-19 07:03:51--  https://github.com/hs-pm/PulseChain-AI/raw/main/data-collection-and-preprocessing/preprocessed.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/hs-pm/PulseChain-AI/main/data-collection-and-preprocessing/preprocessed.zip [following]\n",
            "--2025-06-19 07:03:51--  https://raw.githubusercontent.com/hs-pm/PulseChain-AI/main/data-collection-and-preprocessing/preprocessed.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3343703 (3.2M) [application/zip]\n",
            "Saving to: ‘preprocessed.zip’\n",
            "\n",
            "preprocessed.zip    100%[===================>]   3.19M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-06-19 07:03:52 (50.9 MB/s) - ‘preprocessed.zip’ saved [3343703/3343703]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# prompt: fetch this file from githubhttps://github.com/hs-pm/PulseChain-AI/blob/main/data-collection-and-preprocessing/preprocessed.zip\n",
        "!wget https://github.com/hs-pm/PulseChain-AI/raw/main/data-collection-and-preprocessing/preprocessed.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!unzip /content/preprocessed.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ly3yEdHvFaUS",
        "outputId": "f19632c0-f4de-4ee3-b504-021fe90fdf0c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/preprocessed.zip\n",
            "  inflating: preprocessed_token_terminal_active_addresses_daily.csv  \n",
            "  inflating: preprocessed_token_terminal_unique_transacting_wallets.csv  \n",
            "  inflating: preprocessed_token_terminal_transaction_count.csv  \n",
            "  inflating: preprocessed_token_terminal_total_transaction_fees.csv  \n",
            "  inflating: preprocessed_token_terminal_market_cap_circulating.csv  \n",
            "  inflating: preprocessed_token_terminal_transaction_volume.csv  \n",
            "  inflating: preprocessed_token_terminal_gas_used.csv  \n",
            "  inflating: preprocessed_token_terminal_tokenholder_revenue.csv  \n",
            "  inflating: preprocessed_token_terminal_token_incentives.csv  \n",
            "  inflating: preprocessed_token_terminal_user_dau.csv  \n",
            "  inflating: preprocessed_token_terminal_expenses.csv  \n",
            "  inflating: preprocessed_token_terminal_user_wau.csv  \n",
            "  inflating: preprocessed_token_terminal_gross_profit.csv  \n",
            "  inflating: preprocessed_token_terminal_market_cap_fully_diluted.csv  \n",
            "  inflating: preprocessed_token_terminal_active_developers.csv  \n",
            "  inflating: preprocessed_token_terminal_treasury.csv  \n",
            "  inflating: preprocessed_token_terminal_active_addresses_monthly.csv  \n",
            "  inflating: preprocessed_token_terminal_trading_volume.csv  \n",
            "  inflating: preprocessed_token_terminal_cost_of_revenue.csv  \n",
            "  inflating: preprocessed_token_terminal_earnings.csv  \n",
            "  inflating: preprocessed_token_terminal_trade_count.csv  \n",
            "  inflating: preprocessed_token_terminal_price.csv  \n",
            "  inflating: preprocessed_token_terminal_revenue.csv  \n",
            "  inflating: preprocessed_token_terminal_token_trading_volume.csv  \n",
            "  inflating: preprocessed_token_terminal_transfer_volume.csv  \n",
            "  inflating: preprocessed_token_terminal_fees.csv  \n",
            "  inflating: preprocessed_token_terminal_tvl.csv  \n",
            "  inflating: preprocessed_token_terminal_user_mau.csv  \n",
            "  inflating: preprocessed_token_terminal_fees_supply_side.csv  \n",
            "  inflating: preprocessed_token_terminal_code_commits.csv  \n",
            "  inflating: preprocessed_token_terminal_tokenholders.csv  \n",
            "  inflating: preprocessed_token_terminal_operating_expenses.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: read all csv files and print their name along with their columns\n",
        "\n",
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "csv_files = glob.glob('*.csv')\n",
        "\n",
        "for csv_file in csv_files:\n",
        "    print(f\"File: {csv_file}\")\n",
        "    try:\n",
        "        df = pd.read_csv(csv_file)\n",
        "        print(\"Columns:\", df.columns.tolist())\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {csv_file}: {e}\")\n",
        "    print(\"-\" * 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDe0oFxCFgWZ",
        "outputId": "64f942d2-bfb5-4f17-cd4b-57318818d80b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File: preprocessed_token_terminal_gas_used.csv\n",
            "Columns: ['project_id', 'year_month', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_trade_count.csv\n",
            "Columns: ['project_id', 'year_month', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_treasury.csv\n",
            "Columns: ['project_id', 'year_month', 'timestamp', 'project_name', 'metric_id', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_user_dau.csv\n",
            "Columns: ['project_id', 'year_month', 'timestamp', 'project_name', 'metric_id', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_tvl.csv\n",
            "Columns: ['project_id', 'year_month', 'timestamp', 'project_name', 'metric_id', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_active_addresses_daily.csv\n",
            "Columns: ['project_id', 'year_month', 'timestamp', 'project_name', 'metric_id', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_earnings.csv\n",
            "Columns: ['project_id', 'year_month', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_token_incentives.csv\n",
            "Columns: ['project_id', 'year_month', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_transaction_count.csv\n",
            "Columns: ['project_id', 'year_month', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_trading_volume.csv\n",
            "Columns: ['project_id', 'year_month', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_total_transaction_fees.csv\n",
            "Columns: ['project_id', 'year_month', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_active_developers.csv\n",
            "Columns: ['project_id', 'year_month', 'timestamp', 'project_name', 'metric_id', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_active_addresses_monthly.csv\n",
            "Columns: ['project_id', 'year_month', 'timestamp', 'project_name', 'metric_id', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_user_mau.csv\n",
            "Columns: ['project_id', 'year_month', 'timestamp', 'project_name', 'metric_id', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_transfer_volume.csv\n",
            "Columns: ['project_id', 'year_month', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_cost_of_revenue.csv\n",
            "Columns: ['project_id', 'year_month', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_market_cap_fully_diluted.csv\n",
            "Columns: ['project_id', 'year_month', 'timestamp', 'project_name', 'metric_id', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_market_cap_circulating.csv\n",
            "Columns: ['project_id', 'year_month', 'timestamp', 'project_name', 'metric_id', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_expenses.csv\n",
            "Columns: ['project_id', 'year_month', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_gross_profit.csv\n",
            "Columns: ['project_id', 'year_month', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_revenue.csv\n",
            "Columns: ['project_id', 'year_month', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_code_commits.csv\n",
            "Columns: ['project_id', 'year_month', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_tokenholder_revenue.csv\n",
            "Columns: ['project_id', 'year_month', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_unique_transacting_wallets.csv\n",
            "Columns: ['project_id', 'year_month', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_price.csv\n",
            "Columns: ['project_id', 'year_month', 'timestamp', 'project_name', 'metric_id', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_operating_expenses.csv\n",
            "Columns: ['project_id', 'year_month', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_transaction_volume.csv\n",
            "Columns: ['project_id', 'year_month', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_fees.csv\n",
            "Columns: ['project_id', 'year_month', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_fees_supply_side.csv\n",
            "Columns: ['project_id', 'year_month', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_user_wau.csv\n",
            "Columns: ['project_id', 'year_month', 'timestamp', 'project_name', 'metric_id', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_token_trading_volume.csv\n",
            "Columns: ['project_id', 'year_month', 'value']\n",
            "--------------------\n",
            "File: preprocessed_token_terminal_tokenholders.csv\n",
            "Columns: ['project_id', 'year_month', 'timestamp', 'project_name', 'metric_id', 'value']\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "70ILqSwHtOJZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Directory containing preprocessed files\n",
        "folder = \"/content\"\n",
        "\n",
        "# Load all relevant files into a dictionary\n",
        "def load_csv(metric_name):\n",
        "    path = os.path.join(folder, f\"preprocessed_token_terminal_{metric_name}.csv\")\n",
        "    print(f\"📥 Loading {metric_name} from {path}\")\n",
        "    return pd.read_csv(path)\n",
        "\n",
        "# Load required dataframes\n",
        "metric_names = [\n",
        "    \"market_cap_circulating\", \"market_cap_fully_diluted\", \"revenue\", \"tokenholders\",\n",
        "    \"user_dau\", \"user_mau\", \"fees\", \"fees_supply_side\", \"transaction_volume\",\n",
        "    \"gross_profit\", \"cost_of_revenue\", \"gas_used\", \"transaction_count\",\n",
        "    \"total_transaction_fees\", \"trading_volume\"\n",
        "]\n",
        "\n",
        "dfs = {name: load_csv(name) for name in metric_names}\n",
        "\n",
        "# Clean function\n",
        "def clean(df):\n",
        "    return df[[\"project_id\", \"year_month\", \"value\"]]\n",
        "\n",
        "# Clean all DataFrames\n",
        "for k in dfs:\n",
        "    dfs[k] = clean(dfs[k])\n",
        "    print(f\"✅ Cleaned: {k}, shape = {dfs[k].shape}\")\n",
        "\n",
        "# Join helper\n",
        "def merge(left, right, suffixes=(\"\", \"_r\")):\n",
        "    print(f\"🔗 Merging: {left.shape} + {right.shape}\")\n",
        "    return pd.merge(left, right, on=[\"project_id\", \"year_month\"], how=\"inner\", suffixes=suffixes)\n",
        "\n",
        "# Derived Metrics\n",
        "derived = {}\n",
        "\n",
        "# 1. Circulating P/S Ratio\n",
        "df = merge(dfs[\"market_cap_circulating\"], dfs[\"revenue\"])\n",
        "df[\"value\"] = df[\"value\"] / df[\"value_r\"].replace(0, np.nan)\n",
        "derived[\"circulating_ps_ratio\"] = df\n",
        "\n",
        "# 2. Fully Diluted P/S Ratio\n",
        "derived[\"fdv_ps_ratio\"] = merge(dfs[\"market_cap_fully_diluted\"], dfs[\"revenue\"])\n",
        "derived[\"fdv_ps_ratio\"][\"value\"] = derived[\"fdv_ps_ratio\"][\"value\"] / derived[\"fdv_ps_ratio\"][\"value_r\"]\n",
        "print(\"📊 Derived: fdv_ps_ratio\")\n",
        "\n",
        "# 3. Tokenholder Growth (monthly % growth)\n",
        "df_tok = dfs[\"tokenholders\"].sort_values(by=[\"project_id\", \"year_month\"])\n",
        "df_tok[\"value_prev\"] = df_tok.groupby(\"project_id\")[\"value\"].shift(1)\n",
        "df_tok[\"value\"] = (df_tok[\"value\"] - df_tok[\"value_prev\"]) / df_tok[\"value_prev\"]\n",
        "derived[\"tokenholder_growth\"] = df_tok.drop(columns=[\"value_prev\"])\n",
        "print(\"📊 Derived: tokenholder_growth\")\n",
        "\n",
        "# 4. DAU / MAU\n",
        "derived[\"dau_mau_ratio\"] = merge(dfs[\"user_dau\"], dfs[\"user_mau\"])\n",
        "derived[\"dau_mau_ratio\"][\"value\"] = derived[\"dau_mau_ratio\"][\"value\"] / derived[\"dau_mau_ratio\"][\"value_r\"]\n",
        "print(\"📊 Derived: dau_mau_ratio\")\n",
        "\n",
        "# 5. Protocol Take Rate = (fees - supply_side_fees) / transaction_volume\n",
        "df_take = merge(dfs[\"fees\"], dfs[\"fees_supply_side\"])\n",
        "df_take[\"net_fees\"] = df_take[\"value\"] - df_take[\"value_r\"]\n",
        "\n",
        "df_take = merge(df_take, dfs[\"transaction_volume\"], suffixes=(\"\", \"_tx\"))\n",
        "df_take[\"value\"] = df_take[\"net_fees\"] / df_take[\"value_tx\"].replace(0, np.nan)\n",
        "\n",
        "num_missing = df_take[\"value\"].isna().sum()\n",
        "print(f\"📊 Derived: protocol_take_rate — {num_missing} rows with NaN (likely due to 0 transaction_volume)\")\n",
        "derived[\"protocol_take_rate\"] = df_take[[\"project_id\", \"year_month\", \"value\"]]\n",
        "\n",
        "# 6. Gross Margin = gross_profit / revenue\n",
        "derived[\"gross_margin\"] = merge(dfs[\"gross_profit\"], dfs[\"revenue\"])\n",
        "derived[\"gross_margin\"][\"value\"] = derived[\"gross_margin\"][\"value\"] / derived[\"gross_margin\"][\"value_r\"]\n",
        "print(\"📊 Derived: gross_margin\")\n",
        "\n",
        "# 7. Net Revenue = revenue - cost_of_revenue\n",
        "derived[\"net_revenue\"] = merge(dfs[\"revenue\"], dfs[\"cost_of_revenue\"])\n",
        "derived[\"net_revenue\"][\"value\"] = derived[\"net_revenue\"][\"value\"] - derived[\"net_revenue\"][\"value_r\"]\n",
        "print(\"📊 Derived: net_revenue\")\n",
        "\n",
        "# 8. Gas Used per Transaction\n",
        "derived[\"gas_per_tx\"] = merge(dfs[\"gas_used\"], dfs[\"transaction_count\"])\n",
        "derived[\"gas_per_tx\"][\"gas_per_tx\"] = (\n",
        "    derived[\"gas_per_tx\"][\"value\"] / derived[\"gas_per_tx\"][\"value_r\"].replace(0, np.nan)\n",
        ")\n",
        "print(\"📊 Derived: gas_per_tx\")\n",
        "\n",
        "# 9. Fees per Transaction\n",
        "derived[\"fees_per_tx\"] = merge(dfs[\"fees\"], dfs[\"transaction_count\"])\n",
        "derived[\"fees_per_tx\"][\"fees_per_tx\"] = (\n",
        "    derived[\"fees_per_tx\"][\"value\"] / derived[\"fees_per_tx\"][\"value_r\"].replace(0, np.nan)\n",
        ")\n",
        "print(\"📊 Derived: fees_per_tx\")\n",
        "\n",
        "# 10. Transaction Volume per User (MAU)\n",
        "derived[\"volume_per_user\"] = merge(dfs[\"transaction_volume\"], dfs[\"user_mau\"])\n",
        "derived[\"volume_per_user\"][\"value\"] = derived[\"volume_per_user\"][\"value\"] / derived[\"volume_per_user\"][\"value_r\"].replace(0, np.nan)\n",
        "print(\"📊 Derived: volume_per_user\")\n",
        "\n",
        "# Save all derived metrics\n",
        "output_folder = \"derived_metrics\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for metric, df in derived.items():\n",
        "    df_out = df[[\"project_id\", \"year_month\", \"value\"]]\n",
        "    path = os.path.join(output_folder, f\"{metric}.csv\")\n",
        "    df_out.to_csv(path, index=False)\n",
        "    print(f\"✅ Saved: {path}, shape = {df_out.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3P26BbtHKru",
        "outputId": "2953f3a6-2645-42c0-f5ff-b1695f17d6cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📥 Loading market_cap_circulating from /content/preprocessed_token_terminal_market_cap_circulating.csv\n",
            "📥 Loading market_cap_fully_diluted from /content/preprocessed_token_terminal_market_cap_fully_diluted.csv\n",
            "📥 Loading revenue from /content/preprocessed_token_terminal_revenue.csv\n",
            "📥 Loading tokenholders from /content/preprocessed_token_terminal_tokenholders.csv\n",
            "📥 Loading user_dau from /content/preprocessed_token_terminal_user_dau.csv\n",
            "📥 Loading user_mau from /content/preprocessed_token_terminal_user_mau.csv\n",
            "📥 Loading fees from /content/preprocessed_token_terminal_fees.csv\n",
            "📥 Loading fees_supply_side from /content/preprocessed_token_terminal_fees_supply_side.csv\n",
            "📥 Loading transaction_volume from /content/preprocessed_token_terminal_transaction_volume.csv\n",
            "📥 Loading gross_profit from /content/preprocessed_token_terminal_gross_profit.csv\n",
            "📥 Loading cost_of_revenue from /content/preprocessed_token_terminal_cost_of_revenue.csv\n",
            "📥 Loading gas_used from /content/preprocessed_token_terminal_gas_used.csv\n",
            "📥 Loading transaction_count from /content/preprocessed_token_terminal_transaction_count.csv\n",
            "📥 Loading total_transaction_fees from /content/preprocessed_token_terminal_total_transaction_fees.csv\n",
            "📥 Loading trading_volume from /content/preprocessed_token_terminal_trading_volume.csv\n",
            "✅ Cleaned: market_cap_circulating, shape = (17671, 3)\n",
            "✅ Cleaned: market_cap_fully_diluted, shape = (17718, 3)\n",
            "✅ Cleaned: revenue, shape = (10290, 3)\n",
            "✅ Cleaned: tokenholders, shape = (13557, 3)\n",
            "✅ Cleaned: user_dau, shape = (10234, 3)\n",
            "✅ Cleaned: user_mau, shape = (9983, 3)\n",
            "✅ Cleaned: fees, shape = (10475, 3)\n",
            "✅ Cleaned: fees_supply_side, shape = (9092, 3)\n",
            "✅ Cleaned: transaction_volume, shape = (236, 3)\n",
            "✅ Cleaned: gross_profit, shape = (497, 3)\n",
            "✅ Cleaned: cost_of_revenue, shape = (500, 3)\n",
            "✅ Cleaned: gas_used, shape = (21765, 3)\n",
            "✅ Cleaned: transaction_count, shape = (3010, 3)\n",
            "✅ Cleaned: total_transaction_fees, shape = (30, 3)\n",
            "✅ Cleaned: trading_volume, shape = (3349, 3)\n",
            "🔗 Merging: (17671, 3) + (10290, 3)\n",
            "🔗 Merging: (17718, 3) + (10290, 3)\n",
            "📊 Derived: fdv_ps_ratio\n",
            "📊 Derived: tokenholder_growth\n",
            "🔗 Merging: (10234, 3) + (9983, 3)\n",
            "📊 Derived: dau_mau_ratio\n",
            "🔗 Merging: (10475, 3) + (9092, 3)\n",
            "🔗 Merging: (9065, 5) + (236, 3)\n",
            "📊 Derived: protocol_take_rate — 3 rows with NaN (likely due to 0 transaction_volume)\n",
            "🔗 Merging: (497, 3) + (10290, 3)\n",
            "📊 Derived: gross_margin\n",
            "🔗 Merging: (10290, 3) + (500, 3)\n",
            "📊 Derived: net_revenue\n",
            "🔗 Merging: (21765, 3) + (3010, 3)\n",
            "📊 Derived: gas_per_tx\n",
            "🔗 Merging: (10475, 3) + (3010, 3)\n",
            "📊 Derived: fees_per_tx\n",
            "🔗 Merging: (236, 3) + (9983, 3)\n",
            "📊 Derived: volume_per_user\n",
            "✅ Saved: derived_metrics/circulating_ps_ratio.csv, shape = (7575, 3)\n",
            "✅ Saved: derived_metrics/fdv_ps_ratio.csv, shape = (7283, 3)\n",
            "✅ Saved: derived_metrics/tokenholder_growth.csv, shape = (13557, 3)\n",
            "✅ Saved: derived_metrics/dau_mau_ratio.csv, shape = (9972, 3)\n",
            "✅ Saved: derived_metrics/protocol_take_rate.csv, shape = (164, 3)\n",
            "✅ Saved: derived_metrics/gross_margin.csv, shape = (497, 3)\n",
            "✅ Saved: derived_metrics/net_revenue.csv, shape = (439, 3)\n",
            "✅ Saved: derived_metrics/gas_per_tx.csv, shape = (94, 3)\n",
            "✅ Saved: derived_metrics/fees_per_tx.csv, shape = (1773, 3)\n",
            "✅ Saved: derived_metrics/volume_per_user.csv, shape = (192, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Directory containing preprocessed files\n",
        "folder = \"/content\"\n",
        "\n",
        "# Load all relevant files into a dictionary\n",
        "def load_csv(metric_name):\n",
        "    path = os.path.join(folder, f\"preprocessed_token_terminal_{metric_name}.csv\")\n",
        "    print(f\"📥 Loading {metric_name} from {path}\")\n",
        "    return pd.read_csv(path)\n",
        "\n",
        "# Load required dataframes\n",
        "metric_names = [\n",
        "    \"market_cap_circulating\", \"market_cap_fully_diluted\", \"revenue\", \"tokenholders\",\n",
        "    \"user_dau\", \"user_mau\", \"fees\", \"fees_supply_side\", \"transaction_volume\",\n",
        "    \"gross_profit\", \"cost_of_revenue\", \"gas_used\", \"transaction_count\",\n",
        "    \"total_transaction_fees\", \"trading_volume\"\n",
        "]\n",
        "\n",
        "dfs = {name: load_csv(name) for name in metric_names}\n",
        "\n",
        "# Clean function\n",
        "def clean(df):\n",
        "    return df[[\"project_id\", \"year_month\", \"value\"]]\n",
        "\n",
        "# Clean all DataFrames\n",
        "for k in dfs:\n",
        "    dfs[k] = clean(dfs[k])\n",
        "    print(f\"✅ Cleaned: {k}, shape = {dfs[k].shape}\")\n",
        "\n",
        "# Join helper\n",
        "def merge(left, right, suffixes=(\"\", \"_r\")):\n",
        "    print(f\"🔗 Merging: {left.shape} + {right.shape}\")\n",
        "    return pd.merge(left, right, on=[\"project_id\", \"year_month\"], how=\"inner\", suffixes=suffixes)\n",
        "\n",
        "# Derived Metrics\n",
        "derived = {}\n",
        "\n",
        "# 1. Circulating P/S Ratio\n",
        "df = merge(dfs[\"market_cap_circulating\"], dfs[\"revenue\"])\n",
        "df[\"value\"] = df[\"value\"] / df[\"value_r\"].replace(0, np.nan)\n",
        "derived[\"circulating_ps_ratio\"] = df\n",
        "\n",
        "# 2. Fully Diluted P/S Ratio\n",
        "derived[\"fdv_ps_ratio\"] = merge(dfs[\"market_cap_fully_diluted\"], dfs[\"revenue\"])\n",
        "derived[\"fdv_ps_ratio\"][\"value\"] = derived[\"fdv_ps_ratio\"][\"value\"] / derived[\"fdv_ps_ratio\"][\"value_r\"]\n",
        "print(\"📊 Derived: fdv_ps_ratio\")\n",
        "\n",
        "# 3. Tokenholder Growth\n",
        "df_tok = dfs[\"tokenholders\"].sort_values(by=[\"project_id\", \"year_month\"])\n",
        "df_tok[\"value_prev\"] = df_tok.groupby(\"project_id\")[\"value\"].shift(1)\n",
        "df_tok[\"value\"] = (df_tok[\"value\"] - df_tok[\"value_prev\"]) / df_tok[\"value_prev\"]\n",
        "derived[\"tokenholder_growth\"] = df_tok.drop(columns=[\"value_prev\"])\n",
        "print(\"📊 Derived: tokenholder_growth\")\n",
        "\n",
        "# 4. DAU / MAU\n",
        "derived[\"dau_mau_ratio\"] = merge(dfs[\"user_dau\"], dfs[\"user_mau\"])\n",
        "derived[\"dau_mau_ratio\"][\"value\"] = derived[\"dau_mau_ratio\"][\"value\"] / derived[\"dau_mau_ratio\"][\"value_r\"]\n",
        "print(\"📊 Derived: dau_mau_ratio\")\n",
        "\n",
        "# 5. Protocol Take Rate\n",
        "df_take = merge(dfs[\"fees\"], dfs[\"fees_supply_side\"])\n",
        "df_take[\"net_fees\"] = df_take[\"value\"] - df_take[\"value_r\"]\n",
        "df_take = merge(df_take, dfs[\"transaction_volume\"], suffixes=(\"\", \"_tx\"))\n",
        "df_take[\"value\"] = df_take[\"net_fees\"] / df_take[\"value_tx\"].replace(0, np.nan)\n",
        "derived[\"protocol_take_rate\"] = df_take[[\"project_id\", \"year_month\", \"value\"]]\n",
        "print(f\"📊 Derived: protocol_take_rate — {df_take['value'].isna().sum()} NaNs\")\n",
        "\n",
        "# 6. Gross Margin\n",
        "derived[\"gross_margin\"] = merge(dfs[\"gross_profit\"], dfs[\"revenue\"])\n",
        "derived[\"gross_margin\"][\"value\"] = derived[\"gross_margin\"][\"value\"] / derived[\"gross_margin\"][\"value_r\"]\n",
        "print(\"📊 Derived: gross_margin\")\n",
        "\n",
        "# 7. Net Revenue\n",
        "derived[\"net_revenue\"] = merge(dfs[\"revenue\"], dfs[\"cost_of_revenue\"])\n",
        "derived[\"net_revenue\"][\"value\"] = derived[\"net_revenue\"][\"value\"] - derived[\"net_revenue\"][\"value_r\"]\n",
        "print(\"📊 Derived: net_revenue\")\n",
        "\n",
        "# 8. Gas Used per Transaction\n",
        "derived[\"gas_per_tx\"] = merge(dfs[\"gas_used\"], dfs[\"transaction_count\"])\n",
        "derived[\"gas_per_tx\"][\"gas_per_tx\"] = derived[\"gas_per_tx\"][\"value\"] / derived[\"gas_per_tx\"][\"value_r\"].replace(0, np.nan)\n",
        "print(\"📊 Derived: gas_per_tx\")\n",
        "\n",
        "# 9. Fees per Transaction\n",
        "derived[\"fees_per_tx\"] = merge(dfs[\"fees\"], dfs[\"transaction_count\"])\n",
        "derived[\"fees_per_tx\"][\"fees_per_tx\"] = derived[\"fees_per_tx\"][\"value\"] / derived[\"fees_per_tx\"][\"value_r\"].replace(0, np.nan)\n",
        "print(\"📊 Derived: fees_per_tx\")\n",
        "\n",
        "# 10. Transaction Volume per User (MAU)\n",
        "derived[\"volume_per_user\"] = merge(dfs[\"transaction_volume\"], dfs[\"user_mau\"])\n",
        "derived[\"volume_per_user\"][\"value\"] = derived[\"volume_per_user\"][\"value\"] / derived[\"volume_per_user\"][\"value_r\"].replace(0, np.nan)\n",
        "print(\"📊 Derived: volume_per_user\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load and filter price data\n",
        "price_df = load_csv(\"price\")\n",
        "\n",
        "# Ensure we're only working with 'price' metric\n",
        "price_df = price_df[price_df[\"metric_id\"] == \"price\"]\n",
        "\n",
        "# Use only necessary columns and sort\n",
        "price_df = price_df[[\"project_id\", \"timestamp\", \"value\"]].copy()\n",
        "price_df[\"timestamp\"] = pd.to_datetime(price_df[\"timestamp\"])\n",
        "price_df = price_df.sort_values([\"project_id\", \"timestamp\"])\n",
        "\n",
        "# Calculate metrics\n",
        "price_df[\"momentum_30d\"] = price_df.groupby(\"project_id\")[\"value\"].pct_change(periods=30)\n",
        "price_df[\"log_return\"] = np.log(price_df[\"value\"] / price_df[\"value\"].shift(1))\n",
        "price_df[\"volatility_30d\"] = price_df.groupby(\"project_id\")[\"log_return\"].transform(lambda x: x.rolling(30).std())\n",
        "price_df[\"sharpe_like_ratio\"] = price_df[\"momentum_30d\"] / price_df[\"volatility_30d\"]\n",
        "\n",
        "# Max Drawdown\n",
        "def max_drawdown(prices):\n",
        "    roll_max = prices.rolling(90, min_periods=1).max()\n",
        "    drawdown = prices / roll_max - 1.0\n",
        "    return drawdown.rolling(90, min_periods=1).min()\n",
        "\n",
        "price_df[\"drawdown_max_90d\"] = price_df.groupby(\"project_id\")[\"value\"].transform(max_drawdown)\n",
        "\n",
        "# Correlation with BTC\n",
        "btc_df = price_df[price_df[\"project_id\"] == \"bitcoin\"][[\"timestamp\", \"value\"]].rename(columns={\"value\": \"btc_price\"})\n",
        "price_df = price_df.merge(btc_df, on=\"timestamp\", how=\"left\")\n",
        "\n",
        "def rolling_corr(x):\n",
        "    return x[\"value\"].rolling(30).corr(x[\"btc_price\"])\n",
        "\n",
        "price_df[\"correlation_with_btc\"] = price_df.groupby(\"project_id\").apply(rolling_corr).reset_index(level=0, drop=True)\n",
        "\n",
        "# Add year_month for monthly aggregation\n",
        "price_df[\"year_month\"] = price_df[\"timestamp\"].dt.to_period(\"M\").astype(str)\n",
        "\n",
        "# Store in derived dictionary\n",
        "metrics_to_save = {\n",
        "    \"price_momentum_30d\": \"momentum_30d\",\n",
        "    \"price_volatility_30d\": \"volatility_30d\",\n",
        "    \"sharpe_like_ratio\": \"sharpe_like_ratio\",\n",
        "    \"price_drawdown_max_90d\": \"drawdown_max_90d\",\n",
        "    \"correlation_with_btc\": \"correlation_with_btc\",\n",
        "}\n",
        "\n",
        "for metric_name, col in metrics_to_save.items():\n",
        "    df_out = price_df[[\"project_id\", \"year_month\", col]].dropna().rename(columns={col: \"value\"})\n",
        "    derived[metric_name] = df_out\n",
        "    print(f\"📊 Derived: {metric_name}\")\n",
        "\n",
        "# Save all derived metrics\n",
        "output_folder = \"derived_metrics\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for metric, df in derived.items():\n",
        "    df_out = df[[\"project_id\", \"year_month\", \"value\"]]\n",
        "    path = os.path.join(output_folder, f\"{metric}.csv\")\n",
        "    df_out.to_csv(path, index=False)\n",
        "    print(f\"✅ Saved: {path}, shape = {df_out.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSM6aKLlCwrl",
        "outputId": "345e09f2-bf57-40c8-dd20-8eac6676becd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📥 Loading market_cap_circulating from /content/preprocessed_token_terminal_market_cap_circulating.csv\n",
            "📥 Loading market_cap_fully_diluted from /content/preprocessed_token_terminal_market_cap_fully_diluted.csv\n",
            "📥 Loading revenue from /content/preprocessed_token_terminal_revenue.csv\n",
            "📥 Loading tokenholders from /content/preprocessed_token_terminal_tokenholders.csv\n",
            "📥 Loading user_dau from /content/preprocessed_token_terminal_user_dau.csv\n",
            "📥 Loading user_mau from /content/preprocessed_token_terminal_user_mau.csv\n",
            "📥 Loading fees from /content/preprocessed_token_terminal_fees.csv\n",
            "📥 Loading fees_supply_side from /content/preprocessed_token_terminal_fees_supply_side.csv\n",
            "📥 Loading transaction_volume from /content/preprocessed_token_terminal_transaction_volume.csv\n",
            "📥 Loading gross_profit from /content/preprocessed_token_terminal_gross_profit.csv\n",
            "📥 Loading cost_of_revenue from /content/preprocessed_token_terminal_cost_of_revenue.csv\n",
            "📥 Loading gas_used from /content/preprocessed_token_terminal_gas_used.csv\n",
            "📥 Loading transaction_count from /content/preprocessed_token_terminal_transaction_count.csv\n",
            "📥 Loading total_transaction_fees from /content/preprocessed_token_terminal_total_transaction_fees.csv\n",
            "📥 Loading trading_volume from /content/preprocessed_token_terminal_trading_volume.csv\n",
            "✅ Cleaned: market_cap_circulating, shape = (17671, 3)\n",
            "✅ Cleaned: market_cap_fully_diluted, shape = (17718, 3)\n",
            "✅ Cleaned: revenue, shape = (10290, 3)\n",
            "✅ Cleaned: tokenholders, shape = (13557, 3)\n",
            "✅ Cleaned: user_dau, shape = (10234, 3)\n",
            "✅ Cleaned: user_mau, shape = (9983, 3)\n",
            "✅ Cleaned: fees, shape = (10475, 3)\n",
            "✅ Cleaned: fees_supply_side, shape = (9092, 3)\n",
            "✅ Cleaned: transaction_volume, shape = (236, 3)\n",
            "✅ Cleaned: gross_profit, shape = (497, 3)\n",
            "✅ Cleaned: cost_of_revenue, shape = (500, 3)\n",
            "✅ Cleaned: gas_used, shape = (21765, 3)\n",
            "✅ Cleaned: transaction_count, shape = (3010, 3)\n",
            "✅ Cleaned: total_transaction_fees, shape = (30, 3)\n",
            "✅ Cleaned: trading_volume, shape = (3349, 3)\n",
            "🔗 Merging: (17671, 3) + (10290, 3)\n",
            "🔗 Merging: (17718, 3) + (10290, 3)\n",
            "📊 Derived: fdv_ps_ratio\n",
            "📊 Derived: tokenholder_growth\n",
            "🔗 Merging: (10234, 3) + (9983, 3)\n",
            "📊 Derived: dau_mau_ratio\n",
            "🔗 Merging: (10475, 3) + (9092, 3)\n",
            "🔗 Merging: (9065, 5) + (236, 3)\n",
            "📊 Derived: protocol_take_rate — 3 NaNs\n",
            "🔗 Merging: (497, 3) + (10290, 3)\n",
            "📊 Derived: gross_margin\n",
            "🔗 Merging: (10290, 3) + (500, 3)\n",
            "📊 Derived: net_revenue\n",
            "🔗 Merging: (21765, 3) + (3010, 3)\n",
            "📊 Derived: gas_per_tx\n",
            "🔗 Merging: (10475, 3) + (3010, 3)\n",
            "📊 Derived: fees_per_tx\n",
            "🔗 Merging: (236, 3) + (9983, 3)\n",
            "📊 Derived: volume_per_user\n",
            "📥 Loading price from /content/preprocessed_token_terminal_price.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4-2001614143.py:134: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  price_df[\"correlation_with_btc\"] = price_df.groupby(\"project_id\").apply(rolling_corr).reset_index(level=0, drop=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Derived: price_momentum_30d\n",
            "📊 Derived: price_volatility_30d\n",
            "📊 Derived: sharpe_like_ratio\n",
            "📊 Derived: price_drawdown_max_90d\n",
            "📊 Derived: correlation_with_btc\n",
            "✅ Saved: derived_metrics/circulating_ps_ratio.csv, shape = (7575, 3)\n",
            "✅ Saved: derived_metrics/fdv_ps_ratio.csv, shape = (7283, 3)\n",
            "✅ Saved: derived_metrics/tokenholder_growth.csv, shape = (13557, 3)\n",
            "✅ Saved: derived_metrics/dau_mau_ratio.csv, shape = (9972, 3)\n",
            "✅ Saved: derived_metrics/protocol_take_rate.csv, shape = (164, 3)\n",
            "✅ Saved: derived_metrics/gross_margin.csv, shape = (497, 3)\n",
            "✅ Saved: derived_metrics/net_revenue.csv, shape = (439, 3)\n",
            "✅ Saved: derived_metrics/gas_per_tx.csv, shape = (94, 3)\n",
            "✅ Saved: derived_metrics/fees_per_tx.csv, shape = (1773, 3)\n",
            "✅ Saved: derived_metrics/volume_per_user.csv, shape = (192, 3)\n",
            "✅ Saved: derived_metrics/price_momentum_30d.csv, shape = (7229, 3)\n",
            "✅ Saved: derived_metrics/price_volatility_30d.csv, shape = (7513, 3)\n",
            "✅ Saved: derived_metrics/sharpe_like_ratio.csv, shape = (7229, 3)\n",
            "✅ Saved: derived_metrics/price_drawdown_max_90d.csv, shape = (19322, 3)\n",
            "✅ Saved: derived_metrics/correlation_with_btc.csv, shape = (7126, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "for metric_name, df in derived.items():\n",
        "    print(f\"\\n📈 Metric: {metric_name}           ***************\")\n",
        "\n",
        "    # Drop NaN values to avoid selecting projects with all nulls\n",
        "    non_null_df = df.dropna(subset=[\"value\"])\n",
        "\n",
        "    # Get list of unique project_ids with at least one non-null value\n",
        "    projects = non_null_df[\"project_id\"].unique()\n",
        "\n",
        "    if len(projects) < 3:\n",
        "        print(f\"⚠️ Not enough non-null projects to sample from: {len(projects)} found.\")\n",
        "        continue\n",
        "\n",
        "    # Pick 3 random projects\n",
        "    sampled_projects = random.sample(list(projects), 3)\n",
        "\n",
        "    for project_id in sampled_projects:\n",
        "        print(f\"\\n🔹 Project: {project_id}\")\n",
        "        print(non_null_df[non_null_df[\"project_id\"] == project_id].tail(3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "An1lVtuzj63J",
        "outputId": "5c347ced-fe2c-4e71-9915-658fa1120913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📈 Metric: circulating_ps_ratio           ***************\n",
            "\n",
            "🔹 Project: apeswap\n",
            "    project_id year_month      value      value_r\n",
            "530    apeswap    2025-01  19.650687  8281.628317\n",
            "531    apeswap    2025-02  19.957028  7012.766774\n",
            "532    apeswap    2025-03  28.343347  4632.294888\n",
            "\n",
            "🔹 Project: cap\n",
            "     project_id year_month       value      value_r\n",
            "1555        cap    2024-11  298.889184   360.006765\n",
            "1556        cap    2024-12  590.263270  1467.268343\n",
            "1557        cap    2025-01    7.604536   699.968581\n",
            "\n",
            "🔹 Project: instadapp\n",
            "     project_id year_month       value        value_r\n",
            "3454  instadapp    2025-04  544.090652  335771.803152\n",
            "3455  instadapp    2025-05  308.564546  528767.898113\n",
            "3456  instadapp    2025-06  637.927353  248890.835779\n",
            "\n",
            "📈 Metric: fdv_ps_ratio           ***************\n",
            "\n",
            "🔹 Project: peaq\n",
            "     project_id year_month          value      value_r\n",
            "4818       peaq    2025-04   89854.847148  6151.943161\n",
            "4819       peaq    2025-05  126697.730522  4583.740630\n",
            "4820       peaq    2025-06  601836.014035   766.503961\n",
            "\n",
            "🔹 Project: zyberswap\n",
            "     project_id year_month        value    value_r\n",
            "7280  zyberswap    2025-04   627.866773  48.106528\n",
            "7281  zyberswap    2025-05   627.000502  36.415367\n",
            "7282  zyberswap    2025-06  4516.061822   6.357816\n",
            "\n",
            "🔹 Project: angle\n",
            "    project_id year_month        value       value_r\n",
            "484      angle    2025-04   522.153992  27589.534490\n",
            "485      angle    2025-05  1622.345921   9538.275384\n",
            "486      angle    2025-06  3944.339651   3757.563929\n",
            "\n",
            "📈 Metric: tokenholder_growth           ***************\n",
            "\n",
            "🔹 Project: makerdao\n",
            "     project_id year_month     value\n",
            "7402   makerdao    2025-04  0.154839\n",
            "7403   makerdao    2025-05  0.108939\n",
            "7404   makerdao    2025-06  0.793451\n",
            "\n",
            "🔹 Project: balancer\n",
            "     project_id year_month     value\n",
            "1659   balancer    2025-04  0.002879\n",
            "1660   balancer    2025-05  0.016390\n",
            "1661   balancer    2025-06  0.009756\n",
            "\n",
            "🔹 Project: bounce-finance\n",
            "          project_id year_month     value\n",
            "2667  bounce-finance    2025-04 -0.299824\n",
            "2668  bounce-finance    2025-05  0.019008\n",
            "2669  bounce-finance    2025-06  0.026865\n",
            "\n",
            "📈 Metric: dau_mau_ratio           ***************\n",
            "\n",
            "🔹 Project: viction\n",
            "     project_id year_month     value  value_r\n",
            "9491    viction    2025-04  0.291428   167506\n",
            "9492    viction    2025-05  0.210495   171534\n",
            "9493    viction    2025-06  0.262045   117182\n",
            "\n",
            "🔹 Project: manta\n",
            "     project_id year_month     value  value_r\n",
            "5078      manta    2025-04  0.419292   101049\n",
            "5079      manta    2025-05  0.734348    93916\n",
            "5080      manta    2025-06  0.022292    94565\n",
            "\n",
            "🔹 Project: superrare\n",
            "     project_id year_month     value  value_r\n",
            "8066  superrare    2025-04  0.089947      189\n",
            "8067  superrare    2025-05  0.137363      182\n",
            "8068  superrare    2025-06  0.085308      422\n",
            "\n",
            "📈 Metric: protocol_take_rate           ***************\n",
            "\n",
            "🔹 Project: index-cooperative\n",
            "           project_id year_month     value\n",
            "89  index-cooperative    2025-04  0.038467\n",
            "90  index-cooperative    2025-05  0.015573\n",
            "91  index-cooperative    2025-06  0.029332\n",
            "\n",
            "🔹 Project: axelarnetwork\n",
            "       project_id year_month  value\n",
            "31  axelarnetwork    2025-04    0.0\n",
            "32  axelarnetwork    2025-05    0.0\n",
            "33  axelarnetwork    2025-06    0.0\n",
            "\n",
            "🔹 Project: nexus-mutual\n",
            "       project_id year_month     value\n",
            "159  nexus-mutual    2025-02  0.005507\n",
            "160  nexus-mutual    2025-03  0.005596\n",
            "161  nexus-mutual    2025-04  0.006186\n",
            "\n",
            "📈 Metric: gross_margin           ***************\n",
            "\n",
            "🔹 Project: gravityalpha\n",
            "       project_id year_month     value       value_r\n",
            "247  gravityalpha    2025-04  0.995431  32775.871311\n",
            "248  gravityalpha    2025-05  0.971888  31706.181524\n",
            "249  gravityalpha    2025-06  0.971391  15864.177724\n",
            "\n",
            "🔹 Project: lido-finance\n",
            "       project_id year_month  value       value_r\n",
            "324  lido-finance    2025-04    0.5  4.205651e+06\n",
            "325  lido-finance    2025-05    0.5  5.661256e+06\n",
            "326  lido-finance    2025-06    0.5  2.691463e+06\n",
            "\n",
            "🔹 Project: celo\n",
            "    project_id year_month     value       value_r\n",
            "197       celo    2025-04  0.995197  54747.323573\n",
            "198       celo    2025-05  0.978392  39284.159287\n",
            "199       celo    2025-06  0.966818  13033.709081\n",
            "\n",
            "📈 Metric: net_revenue           ***************\n",
            "\n",
            "🔹 Project: binance-smart-chain\n",
            "              project_id year_month         value      value_r\n",
            "118  binance-smart-chain    2025-04  1.470167e+06  1946.516142\n",
            "119  binance-smart-chain    2025-05  1.574169e+06  4723.129224\n",
            "120  binance-smart-chain    2025-06  7.535511e+05   294.226378\n",
            "\n",
            "🔹 Project: lido-finance\n",
            "       project_id year_month         value       value_r\n",
            "266  lido-finance    2025-04  2.102826e+06  2.102826e+06\n",
            "267  lido-finance    2025-05  2.830628e+06  2.830628e+06\n",
            "268  lido-finance    2025-06  1.345732e+06  1.345732e+06\n",
            "\n",
            "🔹 Project: ethena\n",
            "    project_id year_month         value       value_r\n",
            "177     ethena    2025-04 -1.232160e+06  1.124621e+07\n",
            "178     ethena    2025-05  3.239394e+06  1.723021e+07\n",
            "179     ethena    2025-06 -2.381509e+05  1.130674e+07\n",
            "\n",
            "📈 Metric: gas_per_tx           ***************\n",
            "\n",
            "🔹 Project: uniswap\n",
            "   project_id year_month         value   value_r  gas_per_tx\n",
            "91    uniswap    2025-04  1.435519e+06  23228088    0.061801\n",
            "92    uniswap    2025-05  3.971349e+06  34627851    0.114687\n",
            "93    uniswap    2025-06  1.861791e+06  20804293    0.089491\n",
            "\n",
            "🔹 Project: debridge\n",
            "   project_id year_month          value  value_r  gas_per_tx\n",
            "83   debridge    2025-04   67621.219892    12441    5.435352\n",
            "84   debridge    2025-05  277107.525537    21053   13.162377\n",
            "85   debridge    2025-06  152860.050124    10699   14.287321\n",
            "\n",
            "🔹 Project: axelarnetwork\n",
            "       project_id year_month         value  value_r  gas_per_tx\n",
            "40  axelarnetwork    2025-04  10267.382852    43313    0.237051\n",
            "41  axelarnetwork    2025-05  19631.920274    40959    0.479307\n",
            "42  axelarnetwork    2025-06  15367.475320    17898    0.858614\n",
            "\n",
            "📈 Metric: fees_per_tx           ***************\n",
            "\n",
            "🔹 Project: avalanche\n",
            "    project_id year_month          value   value_r  fees_per_tx\n",
            "131  avalanche    2025-04  234571.107201   8478381     0.027667\n",
            "132  avalanche    2025-05  533287.067189  14484401     0.036818\n",
            "133  avalanche    2025-06  502177.710879  13862815     0.036225\n",
            "\n",
            "🔹 Project: zksync-era\n",
            "      project_id year_month         value  value_r  fees_per_tx\n",
            "1770  zksync-era    2025-04  28234.423735  2058614     0.013715\n",
            "1771  zksync-era    2025-05  33731.585567  1951734     0.017283\n",
            "1772  zksync-era    2025-06  13018.865514   749386     0.017373\n",
            "\n",
            "🔹 Project: binance-smart-chain\n",
            "              project_id year_month         value    value_r  fees_per_tx\n",
            "253  binance-smart-chain    2025-04  1.472350e+07  238547858     0.061721\n",
            "254  binance-smart-chain    2025-05  1.565343e+07  402105378     0.038929\n",
            "255  binance-smart-chain    2025-06  7.372896e+06  274508800     0.026859\n",
            "\n",
            "📈 Metric: volume_per_user           ***************\n",
            "\n",
            "🔹 Project: index-cooperative\n",
            "           project_id year_month         value  value_r\n",
            "94  index-cooperative    2025-04   7588.762564       73\n",
            "95  index-cooperative    2025-05  29511.920809       63\n",
            "96  index-cooperative    2025-06   6060.323937       76\n",
            "\n",
            "🔹 Project: tornado-cash\n",
            "       project_id year_month         value  value_r\n",
            "189  tornado-cash    2025-04  93407.827848     1077\n",
            "190  tornado-cash    2025-05  95406.572643     1697\n",
            "191  tornado-cash    2025-06  63451.612744     1902\n",
            "\n",
            "🔹 Project: nexus-mutual\n",
            "       project_id year_month          value  value_r\n",
            "122  nexus-mutual    2025-04  221151.298968       33\n",
            "123  nexus-mutual    2025-05       0.000000       48\n",
            "124  nexus-mutual    2025-06       0.000000       13\n",
            "Empty DataFrame\n",
            "Columns: [project_id, year_month, value, value_r]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: find derived rows where project_id=bitcoin and show for volume_per_user\n",
        "\n",
        "print(\"\\nBitcoin Volume per User:\")\n",
        "print(derived[\"volume_per_user\"][derived[\"volume_per_user\"][\"project_id\"] == \"bitcoin\"].tail(3))\n",
        "print(dfs[\"transaction_volume\"][dfs[\"transaction_volume\"][\"project_id\"] == \"bitcoin\"].tail(2))\n",
        "print(dfs[\"user_mau\"][dfs[\"user_mau\"][\"project_id\"] == \"bitcoin\"].tail(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTuk4Szgtl71",
        "outputId": "0f65bc29-1b18-4602-d60d-d98ff011f54f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bitcoin Volume per User:\n",
            "Empty DataFrame\n",
            "Columns: [project_id, year_month, value, value_r]\n",
            "Index: []\n",
            "Empty DataFrame\n",
            "Columns: [project_id, year_month, value]\n",
            "Index: []\n",
            "     project_id year_month     value\n",
            "1656    bitcoin    2025-05  10844063\n",
            "1657    bitcoin    2025-06  10918829\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # prompt: read /content/derived_metrics folder\n",
        "# # find out all csvs\n",
        "# # read all csvs\n",
        "# # find out project_ids having at least 1  non-null entry and save them in list for each csv\n",
        "# # use the non-null list to randomly select 3 project_ids for each csv\n",
        "# # print df.tail for each of the selected project_ids\n",
        "\n",
        "# import pandas as pd\n",
        "# derived_csv_files = glob.glob(os.path.join(\"derived_metrics\", \"*.csv\"))\n",
        "\n",
        "# for csv_file_path in derived_csv_files:\n",
        "#     print(f\"\\n--- Processing File: {os.path.basename(csv_file_path)} ---\")\n",
        "#     try:\n",
        "#         df = pd.read_csv(csv_file_path)\n",
        "\n",
        "#         # Find project_ids with at least one non-null value in the 'value' column\n",
        "#         non_null_projects = df.dropna(subset=['value'])['project_id'].unique().tolist()\n",
        "\n",
        "#         if len(non_null_projects) == 0:\n",
        "#             print(\"No projects with non-null values found.\")\n",
        "#             continue\n",
        "\n",
        "#         print(f\"Found {len(non_null_projects)} projects with non-null values.\")\n",
        "\n",
        "#         # Randomly select up to 3 project_ids (or fewer if less than 3 available)\n",
        "#         num_to_sample = min(3, len(non_null_projects))\n",
        "#         sampled_project_ids = random.sample(non_null_projects, num_to_sample)\n",
        "\n",
        "#         print(f\"Randomly selected {num_to_sample} projects: {sampled_project_ids}\")\n",
        "\n",
        "#         # Print df.tail for each selected project_id\n",
        "#         for project_id in sampled_project_ids:\n",
        "#             print(f\"\\nTail of data for project_id: {project_id}\")\n",
        "#             project_df = df[df['project_id'] == project_id].dropna(subset=['value'])\n",
        "#             if not project_df.empty:\n",
        "#                 print(project_df.tail())\n",
        "#             else:\n",
        "#                 print(\"No non-null data points found for this project_id.\")\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error processing {csv_file_path}: {e}\")\n",
        "#     print(\"-\" * 30)"
      ],
      "metadata": {
        "id": "fwVPPen8lHhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # prompt: print latest gas_fee for all project_ids in derived\n",
        "\n",
        "# # Select the gas_per_tx DataFrame\n",
        "# gas_per_tx_df = derived[\"gas_per_tx\"].copy()\n",
        "\n",
        "# # Sort by project and year_month to get the latest entry easily\n",
        "# gas_per_tx_df = gas_per_tx_df.sort_values(by=[\"project_id\", \"year_month\"])\n",
        "\n",
        "# # Get the latest entry for each project_id\n",
        "# latest_gas_fee = gas_per_tx_df.groupby(\"project_id\").tail(1)\n",
        "\n",
        "# print(\"\\nLatest Gas Used per Transaction (gas_per_tx) for all project_ids:\")\n",
        "# latest_gas_fee"
      ],
      "metadata": {
        "id": "lGSufpKCom4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # prompt: print latest gas_fee for all project_ids in derived and print all project_ids for which there is even 1 non null non zero gas_fee\n",
        "\n",
        "# # Find the gas_fees DataFrame in the dfs dictionary\n",
        "# gas_fees_df = dfs.get(\"fees\")\n",
        "\n",
        "# if gas_fees_df is not None:\n",
        "#     print(\"\\n--- Latest Gas Fees for all project_ids ---\")\n",
        "#     # Sort by project_id and year_month to easily get the latest entry for each project\n",
        "#     gas_fees_df_sorted = gas_fees_df.sort_values(by=['project_id', 'year_month'])\n",
        "\n",
        "#     # Get the last entry for each project_id\n",
        "#     latest_gas_fees = gas_fees_df_sorted.groupby('project_id').tail(1)\n",
        "\n",
        "#     # Print the latest gas fees\n",
        "#     if not latest_gas_fees.empty:\n",
        "#         print(latest_gas_fees[['project_id', 'year_month', 'value']])\n",
        "#     else:\n",
        "#         print(\"No gas fees data found.\")\n",
        "\n",
        "#     print(\"\\n--- Project_ids with at least one non-null, non-zero gas fee ---\")\n",
        "#     # Filter for rows where 'value' is not null and not zero\n",
        "#     non_null_zero_gas_fees = gas_fees_df[(gas_fees_df['value'].notna()) & (gas_fees_df['value'] != 0)]\n",
        "\n",
        "#     # Get unique project_ids from the filtered DataFrame\n",
        "#     projects_with_non_null_zero_gas_fees = non_null_zero_gas_fees['project_id'].unique().tolist()\n",
        "\n",
        "#     if projects_with_non_null_zero_gas_fees:\n",
        "#         print(projects_with_non_null_zero_gas_fees)\n",
        "#     else:\n",
        "#         print(\"No project_ids found with a non-null, non-zero gas fee.\")\n",
        "# else:\n",
        "#     print(\"Gas fees DataFrame not found in the loaded data.\")"
      ],
      "metadata": {
        "id": "UfyQaJVftAQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# uniswap_fees_per_tx = derived[\"fees_per_tx\"][derived[\"fees_per_tx\"][\"project_id\"] == \"uniswap\"]\n",
        "\n",
        "# print(\"\\nUniswap Fees per Transaction (fees_per_tx):\")\n",
        "# if not uniswap_fees_per_tx.empty:\n",
        "#     print(uniswap_fees_per_tx.tail())\n",
        "# else:\n",
        "#     print(\"No fees_per_tx data found for Uniswap.\")\n",
        "\n",
        "#     # prompt: from derived show gas_fees, transaction_count for uniswap\n",
        "\n",
        "# # Filter derived gas_per_tx for 'uniswap'\n",
        "# uniswap_gas_per_tx = derived[\"gas_per_tx\"][derived[\"gas_per_tx\"][\"project_id\"] == \"uniswap\"]\n",
        "\n",
        "# # Filter dfs transaction_count for 'uniswap'\n",
        "# uniswap_transaction_count = dfs[\"transaction_count\"][dfs[\"transaction_count\"][\"project_id\"] == \"uniswap\"]\n",
        "\n",
        "# print(\"\\nUniswap Gas Used per Transaction (gas_per_tx):\")\n",
        "# if not uniswap_gas_per_tx.empty:\n",
        "#     print(uniswap_gas_per_tx.tail())\n",
        "# else:\n",
        "#     print(\"No gas_per_tx data found for Uniswap.\")\n",
        "\n",
        "# print(\"\\nUniswap Transaction Count:\")\n",
        "# if not uniswap_transaction_count.empty:\n",
        "#     print(uniswap_transaction_count.tail())\n",
        "# else:\n",
        "#     print(\"No transaction_count data found for Uniswap.\")\n",
        "\n",
        "# # Find the gas_fees DataFrame in the dfs dictionary and filter for 'uniswap'\n",
        "# uniswap_gas_fees = dfs.get(\"fees\")\n",
        "# if uniswap_gas_fees is not None:\n",
        "#     uniswap_gas_fees = uniswap_gas_fees[uniswap_gas_fees[\"project_id\"] == \"uniswap\"]\n",
        "#     print(\"\\nUniswap Gas Fees (derived from 'fees'):\")\n",
        "#     if not uniswap_gas_fees.empty:\n",
        "#         print(uniswap_gas_fees.tail())\n",
        "#     else:\n",
        "#         print(\"No 'fees' data found for Uniswap.\")\n",
        "# else:\n",
        "#     print(\"Gas fees DataFrame (derived from 'fees') not found in the loaded data.\")\n"
      ],
      "metadata": {
        "id": "RDsAeF4svRpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # prompt: dfs[\"market_cap_fully_diluted\"] for kwenta project_id\n",
        "\n",
        "# kwenta_market_cap_fd = dfs[\"market_cap_fully_diluted\"][dfs[\"market_cap_fully_diluted\"][\"project_id\"] == \"kwenta\"]\n",
        "\n",
        "# print(\"\\nKwenta Market Cap Fully Diluted:\")\n",
        "# if not kwenta_market_cap_fd.empty:\n",
        "#     print(kwenta_market_cap_fd.tail())\n",
        "# else:\n",
        "#     print(\"No 'market_cap_fully_diluted' data found for Kwenta.\")\n",
        "# # prompt: dfs[\"market_cap_fully_diluted\"] for kwenta project_id\n",
        "\n",
        "# kwenta_market_cap_fd = dfs[\"revenue\"][dfs[\"revenue\"][\"project_id\"] == \"kwenta\"]\n",
        "\n",
        "# print(\"\\nKwenta revenue Fully Diluted:\")\n",
        "# if not kwenta_market_cap_fd.empty:\n",
        "#     print(kwenta_market_cap_fd.tail())\n",
        "# else:\n",
        "#     print(\"No 'revenue' data found for Kwenta.\")"
      ],
      "metadata": {
        "id": "c3Z1jZ6ivoI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: zip derived_metrics\n",
        "\n",
        "!zip -r derived_metrics.zip derived_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qk_iYsquxn5B",
        "outputId": "622b873b-6c0a-4145-c372-37d42c0436f7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: derived_metrics/ (stored 0%)\n",
            "  adding: derived_metrics/gross_margin.csv (deflated 68%)\n",
            "  adding: derived_metrics/protocol_take_rate.csv (deflated 72%)\n",
            "  adding: derived_metrics/gas_per_tx.csv (deflated 64%)\n",
            "  adding: derived_metrics/tokenholder_growth.csv (deflated 67%)\n",
            "  adding: derived_metrics/price_drawdown_max_90d.csv (deflated 84%)\n",
            "  adding: derived_metrics/price_volatility_30d.csv (deflated 66%)\n",
            "  adding: derived_metrics/price_momentum_30d.csv (deflated 65%)\n",
            "  adding: derived_metrics/fees_per_tx.csv (deflated 63%)\n",
            "  adding: derived_metrics/correlation_with_btc.csv (deflated 66%)\n",
            "  adding: derived_metrics/fdv_ps_ratio.csv (deflated 66%)\n",
            "  adding: derived_metrics/circulating_ps_ratio.csv (deflated 66%)\n",
            "  adding: derived_metrics/sharpe_like_ratio.csv (deflated 64%)\n",
            "  adding: derived_metrics/volume_per_user.csv (deflated 67%)\n",
            "  adding: derived_metrics/net_revenue.csv (deflated 63%)\n",
            "  adding: derived_metrics/dau_mau_ratio.csv (deflated 69%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://api.coingecko.com/api/v3/global\"\n",
        "response = requests.get(url).json()\n",
        "\n",
        "btc_dominance = response[\"data\"][\"market_cap_percentage\"][\"btc\"]\n",
        "eth_dominance = response[\"data\"][\"market_cap_percentage\"][\"eth\"]\n",
        "global_volume_usd = response[\"data\"][\"total_volume\"][\"usd\"]\n",
        "\n",
        "print(f\"BTC Dominance: {btc_dominance:.2f}%\")\n",
        "print(f\"ETH Dominance: {eth_dominance:.2f}%\")\n",
        "print(f\"Global Trading Volume: ${global_volume_usd:,.0f}\")\n"
      ],
      "metadata": {
        "id": "8xgO978n_-3Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec9ae93a-d08d-45bc-dc2d-87a178521c91"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BTC Dominance: 61.74%\n",
            "ETH Dominance: 9.03%\n",
            "Global Trading Volume: $100,488,720,752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Example historical date — MUST be in dd-mm-yyyy format\n",
        "date_str = \"02-01-2021\"\n",
        "\n",
        "url = f\"https://api.coingecko.com/api/v3/coins/bitcoin/history?date={date_str}&localization=false\"\n",
        "resp = requests.get(url)\n",
        "\n",
        "if resp.status_code == 200:\n",
        "    data = resp.json()\n",
        "    if \"market_data\" in data:\n",
        "        usd_market_cap = data[\"market_data\"][\"market_cap\"].get(\"usd\")\n",
        "        print(f\"✅ Bitcoin Market Cap on {date_str}: ${usd_market_cap:,.0f}\")\n",
        "    else:\n",
        "        print(f\"❌ No market_data for Bitcoin on {date_str}\")\n",
        "else:\n",
        "    print(f\"❌ HTTP error {resp.status_code}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OZ1f8NDXT9s",
        "outputId": "fb3e55a9-317d-48f1-b923-df5aad3727c1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ HTTP error 401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "\n",
        "# ---------- Safe request wrapper with 429 handling ----------\n",
        "\n",
        "def safe_request(url, coin_id, date_str, label):\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "    while True:\n",
        "        resp = requests.get(url, headers=headers)\n",
        "        if resp.status_code == 200:\n",
        "            return resp\n",
        "        elif resp.status_code == 429:\n",
        "            print(f\"   ⏳ Rate limited (429) for {label} on {date_str}. Waiting 60s...\")\n",
        "            time.sleep(60)\n",
        "        else:\n",
        "            print(f\"   ❌ HTTP error {resp.status_code} for {label} on {date_str}\")\n",
        "            return None\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "\n",
        "def get_coin_marketcap_on_date(coin_id, date_str):\n",
        "    url = f\"https://api.coingecko.com/api/v3/coins/{coin_id}/history?date={date_str}&localization=false\"\n",
        "    resp = safe_request(url, coin_id, date_str, f\"{coin_id} cap\")\n",
        "    if resp is None:\n",
        "        return None\n",
        "\n",
        "    data = resp.json()\n",
        "    if \"market_data\" not in data:\n",
        "        print(f\"   ❌ No market_data for {coin_id} on {date_str}\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        return data[\"market_data\"][\"market_cap\"][\"usd\"]\n",
        "    except KeyError:\n",
        "        print(f\"   ❌ Missing market_cap['usd'] for {coin_id} on {date_str}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def get_global_volume_on_date(date_str):\n",
        "    url = f\"https://api.coingecko.com/api/v3/coins/bitcoin/history?date={date_str}&localization=false\"\n",
        "    resp = safe_request(url, \"bitcoin\", date_str, \"global volume\")\n",
        "    if resp is None:\n",
        "        return None\n",
        "\n",
        "    data = resp.json()\n",
        "    if \"market_data\" not in data:\n",
        "        print(f\"   ❌ No market_data for volume on {date_str}\")\n",
        "        return None\n",
        "\n",
        "    return data[\"market_data\"][\"total_volume\"].get(\"usd\", None)\n",
        "\n",
        "# ---------- Date Setup ----------\n",
        "\n",
        "today = datetime.today()\n",
        "one_year_ago = today - timedelta(days=365)\n",
        "\n",
        "# Create month start dates from the last 3 months\n",
        "month_starts = pd.date_range(start=one_year_ago.replace(day=1), end=today, freq=\"MS\")\n",
        "\n",
        "# ---------- Retry Logic Per Month ----------\n",
        "\n",
        "def try_fetch_market_data(month_start):\n",
        "    for offset in range(3):  # Try 1st, 2nd, 3rd\n",
        "        try_date = month_start + timedelta(days=offset)\n",
        "        date_str = try_date.strftime(\"%d-%m-%Y\")\n",
        "        print(f\"📆 Trying {date_str}...\")\n",
        "\n",
        "        time.sleep(10)\n",
        "        print(f\"   🔍 Fetching BTC market cap...\")\n",
        "        btc_cap = get_coin_marketcap_on_date(\"bitcoin\", date_str)\n",
        "\n",
        "        time.sleep(10)\n",
        "        print(f\"   🔍 Fetching ETH market cap...\")\n",
        "        eth_cap = get_coin_marketcap_on_date(\"ethereum\", date_str)\n",
        "\n",
        "        time.sleep(10)\n",
        "        print(f\"   🔍 Fetching global volume...\")\n",
        "        global_vol = get_global_volume_on_date(date_str)\n",
        "\n",
        "        if btc_cap is not None and eth_cap is not None:\n",
        "            total_cap = btc_cap + eth_cap\n",
        "            return {\n",
        "                \"year_month\": try_date.strftime(\"%Y-%m\"),\n",
        "                \"timestamp\": try_date,\n",
        "                \"btc_dominance\": btc_cap / total_cap * 100,\n",
        "                \"eth_dominance\": eth_cap / total_cap * 100,\n",
        "                \"global_trading_volume\": global_vol,\n",
        "            }\n",
        "\n",
        "    print(f\"⚠️  Failed to get data for {month_start.strftime('%Y-%m')} after 3 attempts.\")\n",
        "    return None\n",
        "\n",
        "# ---------- Fetch All Months ----------\n",
        "\n",
        "records = []\n",
        "for month_start in month_starts:\n",
        "    record = try_fetch_market_data(month_start)\n",
        "    if record:\n",
        "        records.append(record)\n",
        "\n",
        "# ---------- Format and Save ----------\n",
        "\n",
        "if records:\n",
        "    df = pd.DataFrame(records)\n",
        "    df[\"project_id\"] = \"global\"\n",
        "\n",
        "    df_long = df.melt(\n",
        "        id_vars=[\"project_id\", \"year_month\", \"timestamp\"],\n",
        "        value_vars=[\"btc_dominance\", \"eth_dominance\", \"global_trading_volume\"],\n",
        "        var_name=\"metric_id\",\n",
        "        value_name=\"value\"\n",
        "    )\n",
        "\n",
        "    df_long = df_long[[\"project_id\", \"year_month\", \"timestamp\", \"metric_id\", \"value\"]]\n",
        "    df_long.to_csv(\"derived_metrics/crypto_market_indicators_monthly.csv\", index=False)\n",
        "\n",
        "    print(f\"✅ Saved: derived_metrics/crypto_market_indicators_monthly.csv\")\n",
        "    print(f\"📊 Shape: {df_long.shape}\")\n",
        "else:\n",
        "    print(\"⚠ No data fetched — all months failed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi3VPjfqXo93",
        "outputId": "9db818f3-e945-4249-e01e-898a7805ee07"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📆 Trying 01-06-2024...\n",
            "   🔍 Fetching BTC market cap...\n",
            "   ❌ HTTP error 401 for bitcoin cap on 01-06-2024\n",
            "   🔍 Fetching ETH market cap...\n",
            "   ❌ HTTP error 401 for ethereum cap on 01-06-2024\n",
            "   🔍 Fetching global volume...\n",
            "   ❌ HTTP error 401 for global volume on 01-06-2024\n",
            "📆 Trying 02-06-2024...\n",
            "   🔍 Fetching BTC market cap...\n",
            "   ❌ HTTP error 401 for bitcoin cap on 02-06-2024\n",
            "   🔍 Fetching ETH market cap...\n",
            "   ❌ HTTP error 401 for ethereum cap on 02-06-2024\n",
            "   🔍 Fetching global volume...\n",
            "   ❌ HTTP error 401 for global volume on 02-06-2024\n",
            "📆 Trying 03-06-2024...\n",
            "   🔍 Fetching BTC market cap...\n",
            "   ❌ HTTP error 401 for bitcoin cap on 03-06-2024\n",
            "   🔍 Fetching ETH market cap...\n",
            "   ❌ HTTP error 401 for ethereum cap on 03-06-2024\n",
            "   🔍 Fetching global volume...\n",
            "   ❌ HTTP error 401 for global volume on 03-06-2024\n",
            "⚠️  Failed to get data for 2024-06 after 3 attempts.\n",
            "📆 Trying 01-07-2024...\n",
            "   🔍 Fetching BTC market cap...\n",
            "   🔍 Fetching ETH market cap...\n",
            "   🔍 Fetching global volume...\n",
            "   ⏳ Rate limited (429) for global volume on 01-07-2024. Waiting 60s...\n",
            "📆 Trying 01-08-2024...\n",
            "   🔍 Fetching BTC market cap...\n",
            "   🔍 Fetching ETH market cap...\n",
            "   🔍 Fetching global volume...\n",
            "📆 Trying 01-09-2024...\n",
            "   🔍 Fetching BTC market cap...\n",
            "   🔍 Fetching ETH market cap...\n",
            "   🔍 Fetching global volume...\n",
            "   ⏳ Rate limited (429) for global volume on 01-09-2024. Waiting 60s...\n",
            "📆 Trying 01-10-2024...\n",
            "   🔍 Fetching BTC market cap...\n",
            "   🔍 Fetching ETH market cap...\n",
            "   🔍 Fetching global volume...\n",
            "📆 Trying 01-11-2024...\n",
            "   🔍 Fetching BTC market cap...\n",
            "   🔍 Fetching ETH market cap...\n",
            "   🔍 Fetching global volume...\n",
            "   ⏳ Rate limited (429) for global volume on 01-11-2024. Waiting 60s...\n",
            "📆 Trying 01-12-2024...\n",
            "   🔍 Fetching BTC market cap...\n",
            "   🔍 Fetching ETH market cap...\n",
            "   🔍 Fetching global volume...\n",
            "📆 Trying 01-01-2025...\n",
            "   🔍 Fetching BTC market cap...\n",
            "   🔍 Fetching ETH market cap...\n",
            "   🔍 Fetching global volume...\n",
            "📆 Trying 01-02-2025...\n",
            "   🔍 Fetching BTC market cap...\n",
            "   ⏳ Rate limited (429) for bitcoin cap on 01-02-2025. Waiting 60s...\n",
            "   🔍 Fetching ETH market cap...\n",
            "   🔍 Fetching global volume...\n",
            "📆 Trying 01-03-2025...\n",
            "   🔍 Fetching BTC market cap...\n",
            "   🔍 Fetching ETH market cap...\n",
            "   🔍 Fetching global volume...\n",
            "📆 Trying 01-04-2025...\n",
            "   🔍 Fetching BTC market cap...\n",
            "   🔍 Fetching ETH market cap...\n",
            "   🔍 Fetching global volume...\n",
            "   ⏳ Rate limited (429) for global volume on 01-04-2025. Waiting 60s...\n",
            "📆 Trying 01-05-2025...\n",
            "   🔍 Fetching BTC market cap...\n",
            "   🔍 Fetching ETH market cap...\n",
            "   🔍 Fetching global volume...\n",
            "📆 Trying 01-06-2025...\n",
            "   🔍 Fetching BTC market cap...\n",
            "   🔍 Fetching ETH market cap...\n",
            "   🔍 Fetching global volume...\n",
            "✅ Saved: derived_metrics/crypto_market_indicators_monthly.csv\n",
            "📊 Shape: (36, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_long.to_csv('global_data.csv')"
      ],
      "metadata": {
        "id": "RXbytFhoYFpP"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# Correct endpoint\n",
        "url = \"https://api.llama.fi/v2/historicalChainTvl\"\n",
        "response = requests.get(url)\n",
        "\n",
        "# Ensure success\n",
        "if response.status_code != 200:\n",
        "    raise Exception(f\"Request failed with status {response.status_code}\")\n",
        "\n",
        "# Parse response\n",
        "data = response.json()  # this is a list of dicts\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "df['date'] = pd.to_datetime(df['date'], unit='s')\n",
        "\n",
        "# Group by date to sum TVL across chains\n",
        "df_total = df.groupby('date')['tvl'].sum().resample('M').last().reset_index()\n",
        "df_total['metric_id'] = 'total_tvl_usd'\n",
        "df_total.rename(columns={'tvl': 'value'}, inplace=True)\n",
        "\n",
        "# Preview\n",
        "print(df_total.tail())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLw26quZYMuN",
        "outputId": "6a9542e6-4c12-4322-c24d-769b9dc8868d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         date         value      metric_id\n",
            "82 2025-02-28   98129682473  total_tvl_usd\n",
            "83 2025-03-31   91634365969  total_tvl_usd\n",
            "84 2025-04-30   98712801004  total_tvl_usd\n",
            "85 2025-05-31  112692682454  total_tvl_usd\n",
            "86 2025-06-30  112822459224  total_tvl_usd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-36-1988610659.py:20: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
            "  df_total = df.groupby('date')['tvl'].sum().resample('M').last().reset_index()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "# Download S&P 500 data\n",
        "sp500 = yf.download('^GSPC', start=\"2023-01-01\", interval=\"1d\", group_by='ticker')\n",
        "\n",
        "# Flatten MultiIndex columns if present\n",
        "if isinstance(sp500.columns, pd.MultiIndex):\n",
        "    sp500.columns = sp500.columns.get_level_values(0)\n",
        "\n",
        "# Remove column names and index name\n",
        "sp500.columns.name = None\n",
        "sp500.index.name = None\n",
        "\n",
        "# Confirm: Get first few rows\n",
        "print(sp500.head())\n",
        "\n",
        "print(sp500.columns)\n",
        "sp500.columns=['sp500_index','a','b','c','d']\n",
        "sp500=sp500['sp500_index']\n",
        "sp500 = sp500.reset_index()\n",
        "\n",
        "# Step 2: Rename the index column to 'month'\n",
        "sp500.rename(columns={'index': 'month'}, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsJ7TdZIjSHe",
        "outputId": "2c84311f-be73-4489-ef30-70cda94282af"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-64-4105661863.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  sp500 = yf.download('^GSPC', start=\"2023-01-01\", interval=\"1d\", group_by='ticker')\n",
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  ^GSPC        ^GSPC        ^GSPC        ^GSPC       ^GSPC\n",
            "2023-01-03  3853.290039  3878.459961  3794.330078  3824.139893  3959140000\n",
            "2023-01-04  3840.360107  3873.159912  3815.770020  3852.969971  4414080000\n",
            "2023-01-05  3839.739990  3839.739990  3802.419922  3808.100098  3893450000\n",
            "2023-01-06  3823.370117  3906.189941  3809.560059  3895.080078  3923560000\n",
            "2023-01-09  3910.820068  3950.570068  3890.419922  3892.090088  4311770000\n",
            "Index(['^GSPC', '^GSPC', '^GSPC', '^GSPC', '^GSPC'], dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sp500.rename(columns={'sp500_index': 'value'}, inplace=True)\n",
        "sp500['metric_id']='sp500_index'"
      ],
      "metadata": {
        "id": "W2U_ymbjkaE4"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sp500"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "48Vh_fLVlQtu",
        "outputId": "a32c2919-9e70-4189-99c6-3c2dd81d05ed"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         month        value       metric    metric_id\n",
              "0   2023-01-03  3853.290039  sp500_index  sp500_index\n",
              "1   2023-01-04  3840.360107  sp500_index  sp500_index\n",
              "2   2023-01-05  3839.739990  sp500_index  sp500_index\n",
              "3   2023-01-06  3823.370117  sp500_index  sp500_index\n",
              "4   2023-01-09  3910.820068  sp500_index  sp500_index\n",
              "..         ...          ...          ...          ...\n",
              "612 2025-06-12  6009.899902  sp500_index  sp500_index\n",
              "613 2025-06-13  6000.560059  sp500_index  sp500_index\n",
              "614 2025-06-16  6004.000000  sp500_index  sp500_index\n",
              "615 2025-06-17  6012.149902  sp500_index  sp500_index\n",
              "616 2025-06-18  5987.930176  sp500_index  sp500_index\n",
              "\n",
              "[617 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8cd051d7-eac6-4233-9d69-bc8ada94ca4a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>value</th>\n",
              "      <th>metric</th>\n",
              "      <th>metric_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-01-03</td>\n",
              "      <td>3853.290039</td>\n",
              "      <td>sp500_index</td>\n",
              "      <td>sp500_index</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2023-01-04</td>\n",
              "      <td>3840.360107</td>\n",
              "      <td>sp500_index</td>\n",
              "      <td>sp500_index</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2023-01-05</td>\n",
              "      <td>3839.739990</td>\n",
              "      <td>sp500_index</td>\n",
              "      <td>sp500_index</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2023-01-06</td>\n",
              "      <td>3823.370117</td>\n",
              "      <td>sp500_index</td>\n",
              "      <td>sp500_index</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2023-01-09</td>\n",
              "      <td>3910.820068</td>\n",
              "      <td>sp500_index</td>\n",
              "      <td>sp500_index</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>612</th>\n",
              "      <td>2025-06-12</td>\n",
              "      <td>6009.899902</td>\n",
              "      <td>sp500_index</td>\n",
              "      <td>sp500_index</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>613</th>\n",
              "      <td>2025-06-13</td>\n",
              "      <td>6000.560059</td>\n",
              "      <td>sp500_index</td>\n",
              "      <td>sp500_index</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614</th>\n",
              "      <td>2025-06-16</td>\n",
              "      <td>6004.000000</td>\n",
              "      <td>sp500_index</td>\n",
              "      <td>sp500_index</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>615</th>\n",
              "      <td>2025-06-17</td>\n",
              "      <td>6012.149902</td>\n",
              "      <td>sp500_index</td>\n",
              "      <td>sp500_index</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>616</th>\n",
              "      <td>2025-06-18</td>\n",
              "      <td>5987.930176</td>\n",
              "      <td>sp500_index</td>\n",
              "      <td>sp500_index</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>617 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8cd051d7-eac6-4233-9d69-bc8ada94ca4a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8cd051d7-eac6-4233-9d69-bc8ada94ca4a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8cd051d7-eac6-4233-9d69-bc8ada94ca4a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-31d8f483-a456-416d-9b4c-c87b4dd7d4cf\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-31d8f483-a456-416d-9b4c-c87b4dd7d4cf')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-31d8f483-a456-416d-9b4c-c87b4dd7d4cf button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_ddf1950b-aae0-4bc9-af58-dceaa656209b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('sp500')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ddf1950b-aae0-4bc9-af58-dceaa656209b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('sp500');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "sp500",
              "summary": "{\n  \"name\": \"sp500\",\n  \"rows\": 617,\n  \"fields\": [\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2023-01-03 00:00:00\",\n        \"max\": \"2025-06-18 00:00:00\",\n        \"num_unique_values\": 617,\n        \"samples\": [\n          \"2023-03-15 00:00:00\",\n          \"2025-04-29 00:00:00\",\n          \"2023-05-02 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 700.6377997072391,\n        \"min\": 3823.3701171875,\n        \"max\": 6134.5,\n        \"num_unique_values\": 617,\n        \"samples\": [\n          3876.739990234375,\n          5508.8701171875,\n          4164.10009765625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"sp500_index\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metric_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"sp500_index\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# --- 1. Coingecko dominance and volume ---\n",
        "df_long['year_month'] = pd.to_datetime(df_long['timestamp']).dt.to_period('M').astype(str)\n",
        "df_cg = df_long.groupby(['year_month', 'metric_id'])['value'].last().reset_index()\n",
        "\n",
        "# --- 2. TVL ---\n",
        "df_total['year_month'] = pd.to_datetime(df_total['date']).dt.to_period('M').astype(str)\n",
        "df_tvl = df_total.groupby(['year_month', 'metric_id'])['value'].last().reset_index()\n",
        "\n",
        "# --- 3. S&P 500 ---\n",
        "df_sp = sp500.copy()\n",
        "df_sp['year_month'] = pd.to_datetime(df_sp['month']).dt.to_period('M').astype(str)\n",
        "df_sp = df_sp[['year_month', 'metric_id', 'value']]\n",
        "\n",
        "# --- 4. Combine all ---\n",
        "global_market = pd.concat([df_cg, df_tvl, df_sp], ignore_index=True)\n",
        "\n",
        "# --- 5. Clean and sort ---\n",
        "global_market = global_market.dropna()\n",
        "global_market = global_market.sort_values(by=['year_month', 'metric_id'])\n",
        "\n",
        "# --- 6. Save ---\n",
        "global_market.to_csv('global_market.csv', index=False)\n"
      ],
      "metadata": {
        "id": "UaNsOw8plahl"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: list all csvs in /content/derived_metrics\n",
        "# and all csvs in /content\n",
        "\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# List CSVs in /content/derived_metrics\n",
        "print(\"CSV files in /content/derived_metrics:\")\n",
        "derived_metrics_csvs = glob.glob('/content/derived_metrics/*.csv')\n",
        "for f in derived_metrics_csvs:\n",
        "    print(f)\n",
        "\n",
        "print(\"\\nCSV files in /content:\")\n",
        "# List CSVs in /content\n",
        "content_csvs = glob.glob('/content/*.csv')\n",
        "for f in content_csvs:\n",
        "  print(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZZcJ_rjm_hD",
        "outputId": "3c2c1b03-6690-4dcd-9401-c227c0eeeadd"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV files in /content/derived_metrics:\n",
            "/content/derived_metrics/gross_margin.csv\n",
            "/content/derived_metrics/crypto_market_indicators_monthly.csv\n",
            "/content/derived_metrics/protocol_take_rate.csv\n",
            "/content/derived_metrics/gas_per_tx.csv\n",
            "/content/derived_metrics/tokenholder_growth.csv\n",
            "/content/derived_metrics/price_drawdown_max_90d.csv\n",
            "/content/derived_metrics/price_volatility_30d.csv\n",
            "/content/derived_metrics/price_momentum_30d.csv\n",
            "/content/derived_metrics/fees_per_tx.csv\n",
            "/content/derived_metrics/correlation_with_btc.csv\n",
            "/content/derived_metrics/fdv_ps_ratio.csv\n",
            "/content/derived_metrics/circulating_ps_ratio.csv\n",
            "/content/derived_metrics/sharpe_like_ratio.csv\n",
            "/content/derived_metrics/volume_per_user.csv\n",
            "/content/derived_metrics/net_revenue.csv\n",
            "/content/derived_metrics/dau_mau_ratio.csv\n",
            "\n",
            "CSV files in /content:\n",
            "/content/preprocessed_token_terminal_gas_used.csv\n",
            "/content/preprocessed_token_terminal_trade_count.csv\n",
            "/content/preprocessed_token_terminal_treasury.csv\n",
            "/content/preprocessed_token_terminal_user_dau.csv\n",
            "/content/preprocessed_token_terminal_tvl.csv\n",
            "/content/preprocessed_token_terminal_active_addresses_daily.csv\n",
            "/content/preprocessed_token_terminal_earnings.csv\n",
            "/content/preprocessed_token_terminal_token_incentives.csv\n",
            "/content/preprocessed_token_terminal_transaction_count.csv\n",
            "/content/preprocessed_token_terminal_trading_volume.csv\n",
            "/content/preprocessed_token_terminal_total_transaction_fees.csv\n",
            "/content/preprocessed_token_terminal_active_developers.csv\n",
            "/content/preprocessed_token_terminal_active_addresses_monthly.csv\n",
            "/content/preprocessed_token_terminal_user_mau.csv\n",
            "/content/preprocessed_token_terminal_transfer_volume.csv\n",
            "/content/preprocessed_token_terminal_cost_of_revenue.csv\n",
            "/content/preprocessed_token_terminal_market_cap_fully_diluted.csv\n",
            "/content/preprocessed_token_terminal_market_cap_circulating.csv\n",
            "/content/preprocessed_token_terminal_expenses.csv\n",
            "/content/preprocessed_token_terminal_gross_profit.csv\n",
            "/content/preprocessed_token_terminal_revenue.csv\n",
            "/content/preprocessed_token_terminal_code_commits.csv\n",
            "/content/preprocessed_token_terminal_tokenholder_revenue.csv\n",
            "/content/preprocessed_token_terminal_unique_transacting_wallets.csv\n",
            "/content/preprocessed_token_terminal_price.csv\n",
            "/content/global_market.csv\n",
            "/content/preprocessed_token_terminal_operating_expenses.csv\n",
            "/content/preprocessed_token_terminal_transaction_volume.csv\n",
            "/content/preprocessed_token_terminal_fees.csv\n",
            "/content/preprocessed_token_terminal_fees_supply_side.csv\n",
            "/content/preprocessed_token_terminal_user_wau.csv\n",
            "/content/preprocessed_token_terminal_token_trading_volume.csv\n",
            "/content/preprocessed_token_terminal_tokenholders.csv\n",
            "/content/global_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ljY79W2mrA8e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}